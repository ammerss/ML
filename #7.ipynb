{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class Linear(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        self.number_class   = num_classes\n",
    "\n",
    "        _size_image     = 100* 100\n",
    "        _num1           = 50\n",
    "        _num2           = 50\n",
    "        \n",
    "        self.fc1        = nn.Linear(_size_image, _num1, bias=True)\n",
    "        self.fc2        = nn.Linear(_num1, _num2, bias=True)\n",
    "        self.fc3        = nn.Linear(_num2, num_classes, bias=True)\n",
    "\n",
    "        self.fc_layer1  = nn.Sequential(self.fc1, nn.ReLU(True))\n",
    "        self.fc_layer2  = nn.Sequential(self.fc2, nn.ReLU(True))\n",
    "        self.fc_layer3  = nn.Sequential(self.fc3, nn.ReLU(True))\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        \n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc2.bias.data.zero_()\n",
    "        self.fc3.bias.data.zero_()\n",
    "        \n",
    "        self.classifier = nn.Sequential(self.fc_layer1, self.fc_layer2, self.fc_layer3)\n",
    "        #self._initialize_weight()        \n",
    "        \n",
    "    def _initialize_weight(self):\n",
    "        #Linear = m.__class__.__name__\n",
    "        for m in self.modules():\n",
    "            \n",
    "            n = m.in_features\n",
    "            \n",
    "            m.weight.data.uniform_(- 1.0 / math.sqrt(n), 1.0 / math.sqrt(n))\n",
    "\n",
    "            if m.bias is not None:\n",
    "\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'loss_train_mean': 0.07024134039548167, 'loss_train_std': 0.006351471050826842, 'accuracy_train': 55.98831548198637}\n",
      "{'loss_test': 0.06885433802381158, 'accuracy_test': 52.34375}\n",
      "1\n",
      "{'loss_train_mean': 0.06733803706923074, 'loss_train_std': 0.004141584824262507, 'accuracy_train': 62.804284323271666}\n",
      "{'loss_test': 0.06910228740889579, 'accuracy_test': 50.78125}\n",
      "2\n",
      "{'loss_train_mean': 0.0660668504469603, 'loss_train_std': 0.0047103597258013755, 'accuracy_train': 63.87536514118793}\n",
      "{'loss_test': 0.05778232298325747, 'accuracy_test': 78.125}\n",
      "3\n",
      "{'loss_train_mean': 0.06188346541456972, 'loss_train_std': 0.006493312151659639, 'accuracy_train': 69.32814021421616}\n",
      "{'loss_test': 0.051716232439503074, 'accuracy_test': 81.25}\n",
      "4\n",
      "{'loss_train_mean': 0.05867989764712886, 'loss_train_std': 0.007125917710585718, 'accuracy_train': 73.51509250243427}\n",
      "{'loss_test': 0.04810676095075905, 'accuracy_test': 84.765625}\n",
      "5\n",
      "{'loss_train_mean': 0.05669036688652515, 'loss_train_std': 0.007152097112795123, 'accuracy_train': 73.70983446932814}\n",
      "{'loss_test': 0.04524832247989252, 'accuracy_test': 87.5}\n",
      "6\n",
      "{'loss_train_mean': 0.054748389802759465, 'loss_train_std': 0.007437583483612858, 'accuracy_train': 74.68354430379746}\n",
      "{'loss_test': 0.04246124468045309, 'accuracy_test': 88.28125}\n",
      "7\n",
      "{'loss_train_mean': 0.053349522359658876, 'loss_train_std': 0.008545317071737859, 'accuracy_train': 74.87828627069133}\n",
      "{'loss_test': 0.0399783470784314, 'accuracy_test': 89.453125}\n",
      "8\n",
      "{'loss_train_mean': 0.052077468622078016, 'loss_train_std': 0.00871535669429792, 'accuracy_train': 77.21518987341773}\n",
      "{'loss_test': 0.041328819293994457, 'accuracy_test': 83.203125}\n",
      "9\n",
      "{'loss_train_mean': 0.050836071888715986, 'loss_train_std': 0.00993168750835424, 'accuracy_train': 77.60467380720546}\n",
      "{'loss_test': 0.03721094428328797, 'accuracy_test': 87.5}\n",
      "10\n",
      "{'loss_train_mean': 0.04990189814121152, 'loss_train_std': 0.008419911351364965, 'accuracy_train': 77.31256085686465}\n",
      "{'loss_test': 0.03668530628783628, 'accuracy_test': 85.546875}\n",
      "11\n",
      "{'loss_train_mean': 0.04893125472551575, 'loss_train_std': 0.009677516847242953, 'accuracy_train': 77.50730282375852}\n",
      "{'loss_test': 0.03449675132287666, 'accuracy_test': 88.671875}\n",
      "12\n",
      "{'loss_train_mean': 0.04796838061819461, 'loss_train_std': 0.008740585228557966, 'accuracy_train': 78.09152872444011}\n",
      "{'loss_test': 0.03461352296289988, 'accuracy_test': 87.109375}\n",
      "13\n",
      "{'loss_train_mean': 0.047266439318491574, 'loss_train_std': 0.009847042202233177, 'accuracy_train': 79.25998052580331}\n",
      "{'loss_test': 0.03275002638110891, 'accuracy_test': 89.453125}\n",
      "14\n",
      "{'loss_train_mean': 0.04663597662389363, 'loss_train_std': 0.009254571987188214, 'accuracy_train': 78.48101265822785}\n",
      "{'loss_test': 0.0342548344633542, 'accuracy_test': 85.15625}\n",
      "15\n",
      "{'loss_train_mean': 0.045561060226740675, 'loss_train_std': 0.009720027675041928, 'accuracy_train': 79.45472249269717}\n",
      "{'loss_test': 0.03349300942500122, 'accuracy_test': 85.9375}\n",
      "16\n",
      "{'loss_train_mean': 0.044969442811240434, 'loss_train_std': 0.010257209532351772, 'accuracy_train': 79.64946445959104}\n",
      "{'loss_test': 0.03497281190357171, 'accuracy_test': 84.375}\n",
      "17\n",
      "{'loss_train_mean': 0.044389454819954384, 'loss_train_std': 0.011117274229957484, 'accuracy_train': 80.13631937682571}\n",
      "{'loss_test': 0.0327185817877762, 'accuracy_test': 85.546875}\n",
      "18\n",
      "{'loss_train_mean': 0.043777167501545484, 'loss_train_std': 0.010863041741070709, 'accuracy_train': 81.0126582278481}\n",
      "{'loss_test': 0.03157445404212922, 'accuracy_test': 87.890625}\n",
      "19\n",
      "{'loss_train_mean': 0.042970784188308915, 'loss_train_std': 0.009094722022401053, 'accuracy_train': 81.5968841285297}\n",
      "{'loss_test': 0.029928574032965116, 'accuracy_test': 89.453125}\n",
      "20\n",
      "{'loss_train_mean': 0.042497214367006104, 'loss_train_std': 0.010147545978817962, 'accuracy_train': 81.49951314508276}\n",
      "{'loss_test': 0.031118616898311302, 'accuracy_test': 86.71875}\n",
      "21\n",
      "{'loss_train_mean': 0.04166202839055768, 'loss_train_std': 0.009940895333287379, 'accuracy_train': 82.37585199610515}\n",
      "{'loss_test': 0.030526664078934118, 'accuracy_test': 87.890625}\n",
      "22\n",
      "{'loss_train_mean': 0.04142163404975287, 'loss_train_std': 0.009127050837208724, 'accuracy_train': 83.15481986368063}\n",
      "{'loss_test': 0.0294512639666209, 'accuracy_test': 88.28125}\n",
      "23\n",
      "{'loss_train_mean': 0.040839557971769164, 'loss_train_std': 0.010211164562874764, 'accuracy_train': 82.96007789678676}\n",
      "{'loss_test': 0.0372993699129438, 'accuracy_test': 79.296875}\n",
      "24\n",
      "{'loss_train_mean': 0.04066348516081309, 'loss_train_std': 0.010889521702076745, 'accuracy_train': 83.0574488802337}\n",
      "{'loss_test': 0.03250263349036686, 'accuracy_test': 84.765625}\n",
      "25\n",
      "{'loss_train_mean': 0.03995948547959823, 'loss_train_std': 0.01133132328399753, 'accuracy_train': 83.34956183057449}\n",
      "{'loss_test': 0.035756608966039494, 'accuracy_test': 81.640625}\n",
      "26\n",
      "{'loss_train_mean': 0.0394977351332835, 'loss_train_std': 0.010510416161010802, 'accuracy_train': 83.64167478091528}\n",
      "{'loss_test': 0.03016907919663936, 'accuracy_test': 86.71875}\n",
      "27\n",
      "{'loss_train_mean': 0.03902888144889586, 'loss_train_std': 0.010402858626862596, 'accuracy_train': 84.22590068159688}\n",
      "{'loss_test': 0.03854772575868992, 'accuracy_test': 78.515625}\n",
      "28\n",
      "{'loss_train_mean': 0.0386497768755594, 'loss_train_std': 0.010603950313879694, 'accuracy_train': 84.81012658227849}\n",
      "{'loss_test': 0.0285693881669431, 'accuracy_test': 89.84375}\n",
      "29\n",
      "{'loss_train_mean': 0.038290485272625775, 'loss_train_std': 0.010178972058657221, 'accuracy_train': 84.42064264849076}\n",
      "{'loss_test': 0.02936229396436829, 'accuracy_test': 87.890625}\n",
      "30\n",
      "{'loss_train_mean': 0.03791802656758013, 'loss_train_std': 0.010903989596195042, 'accuracy_train': 85.00486854917234}\n",
      "{'loss_test': 0.02847787761129439, 'accuracy_test': 88.671875}\n",
      "31\n",
      "{'loss_train_mean': 0.03777786442873051, 'loss_train_std': 0.010915775345004692, 'accuracy_train': 85.19961051606622}\n",
      "{'loss_test': 0.028756428451742977, 'accuracy_test': 88.28125}\n",
      "32\n",
      "{'loss_train_mean': 0.03723998924358212, 'loss_train_std': 0.010865021713789788, 'accuracy_train': 85.00486854917234}\n",
      "{'loss_test': 0.028820728250138927, 'accuracy_test': 88.28125}\n",
      "33\n",
      "{'loss_train_mean': 0.03709115750581315, 'loss_train_std': 0.011936224294664491, 'accuracy_train': 85.39435248296007}\n",
      "{'loss_test': 0.03122498167795129, 'accuracy_test': 84.765625}\n",
      "34\n",
      "{'loss_train_mean': 0.0365261813555941, 'loss_train_std': 0.010961281046986987, 'accuracy_train': 85.97857838364168}\n",
      "{'loss_test': 0.02842877657531062, 'accuracy_test': 88.671875}\n",
      "35\n",
      "{'loss_train_mean': 0.036107152458616176, 'loss_train_std': 0.010179284153833729, 'accuracy_train': 85.88120740019474}\n",
      "{'loss_test': 0.03023566435149405, 'accuracy_test': 85.546875}\n",
      "36\n",
      "{'loss_train_mean': 0.03590564193945487, 'loss_train_std': 0.010732042859285506, 'accuracy_train': 86.56280428432328}\n",
      "{'loss_test': 0.029632972458784934, 'accuracy_test': 86.328125}\n",
      "37\n",
      "{'loss_train_mean': 0.03556590724255936, 'loss_train_std': 0.009113661947979435, 'accuracy_train': 86.3680623174294}\n",
      "{'loss_test': 0.028506146380095743, 'accuracy_test': 89.0625}\n",
      "38\n",
      "{'loss_train_mean': 0.035278732754321106, 'loss_train_std': 0.010775635216881114, 'accuracy_train': 86.56280428432328}\n",
      "{'loss_test': 0.0288376033277018, 'accuracy_test': 87.890625}\n",
      "39\n",
      "{'loss_train_mean': 0.03478846109359836, 'loss_train_std': 0.009790547794951235, 'accuracy_train': 86.56280428432328}\n",
      "{'loss_test': 0.029552479601989035, 'accuracy_test': 86.328125}\n",
      "40\n",
      "{'loss_train_mean': 0.034529345299681755, 'loss_train_std': 0.010606843896120217, 'accuracy_train': 87.34177215189874}\n",
      "{'loss_test': 0.028659223673457745, 'accuracy_test': 87.5}\n",
      "41\n",
      "{'loss_train_mean': 0.034350761293786246, 'loss_train_std': 0.011062353693088217, 'accuracy_train': 87.5365141187926}\n",
      "{'loss_test': 0.02875104504346382, 'accuracy_test': 87.5}\n",
      "42\n",
      "{'loss_train_mean': 0.034009066455572556, 'loss_train_std': 0.010258344176971393, 'accuracy_train': 87.2444011684518}\n",
      "{'loss_test': 0.03510355670005083, 'accuracy_test': 82.03125}\n",
      "43\n",
      "{'loss_train_mean': 0.033670764617962916, 'loss_train_std': 0.010108547372500882, 'accuracy_train': 87.5365141187926}\n",
      "{'loss_test': 0.028557127065141685, 'accuracy_test': 87.890625}\n",
      "44\n",
      "{'loss_train_mean': 0.03356696320968924, 'loss_train_std': 0.009964710652983908, 'accuracy_train': 87.63388510223953}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_test': 0.030377010501979385, 'accuracy_test': 84.765625}\n",
      "45\n",
      "{'loss_train_mean': 0.0331717085088093, 'loss_train_std': 0.011079446896514663, 'accuracy_train': 87.5365141187926}\n",
      "{'loss_test': 0.030206849980459083, 'accuracy_test': 85.546875}\n",
      "46\n",
      "{'loss_train_mean': 0.032807848713103674, 'loss_train_std': 0.010224727212247533, 'accuracy_train': 88.1207400194742}\n",
      "{'loss_test': 0.02826544597701286, 'accuracy_test': 89.0625}\n",
      "47\n",
      "{'loss_train_mean': 0.032555092922857506, 'loss_train_std': 0.010588404576723106, 'accuracy_train': 88.41285296981499}\n",
      "{'loss_test': 0.0286677696640254, 'accuracy_test': 87.109375}\n",
      "48\n",
      "{'loss_train_mean': 0.03247886822764321, 'loss_train_std': 0.01087061459254923, 'accuracy_train': 88.51022395326193}\n",
      "{'loss_test': 0.03221242988365702, 'accuracy_test': 83.984375}\n",
      "49\n",
      "{'loss_train_mean': 0.03211459348006652, 'loss_train_std': 0.009307521251647737, 'accuracy_train': 88.1207400194742}\n",
      "{'loss_test': 0.03397563557518879, 'accuracy_test': 82.421875}\n",
      "50\n",
      "{'loss_train_mean': 0.031842790985281026, 'loss_train_std': 0.009060095136241257, 'accuracy_train': 88.9970788704966}\n",
      "{'loss_test': 0.028200462631502887, 'accuracy_test': 88.671875}\n",
      "51\n",
      "{'loss_train_mean': 0.031618013401385314, 'loss_train_std': 0.009729992539753127, 'accuracy_train': 88.80233690360272}\n",
      "{'loss_test': 0.0288793106956291, 'accuracy_test': 87.109375}\n",
      "52\n",
      "{'loss_train_mean': 0.03147089973030077, 'loss_train_std': 0.011854637251681666, 'accuracy_train': 89.58130477117818}\n",
      "{'loss_test': 0.029350579708989244, 'accuracy_test': 86.71875}\n",
      "53\n",
      "{'loss_train_mean': 0.031124377974028724, 'loss_train_std': 0.009135917237087324, 'accuracy_train': 89.87341772151899}\n",
      "{'loss_test': 0.02963684946007561, 'accuracy_test': 86.328125}\n",
      "54\n",
      "{'loss_train_mean': 0.03078097922833386, 'loss_train_std': 0.008902807491140459, 'accuracy_train': 89.28919182083739}\n",
      "{'loss_test': 0.03041863057296723, 'accuracy_test': 85.15625}\n",
      "55\n",
      "{'loss_train_mean': 0.030660354597145247, 'loss_train_std': 0.009785400172256938, 'accuracy_train': 89.87341772151899}\n",
      "{'loss_test': 0.029490807057300117, 'accuracy_test': 86.71875}\n",
      "56\n",
      "{'loss_train_mean': 0.03037644496779171, 'loss_train_std': 0.009377941414286023, 'accuracy_train': 90.65238558909445}\n",
      "{'loss_test': 0.028483179565228056, 'accuracy_test': 87.109375}\n",
      "57\n",
      "{'loss_train_mean': 0.03006407014105918, 'loss_train_std': 0.009584965499873269, 'accuracy_train': 90.26290165530672}\n",
      "{'loss_test': 0.03079515663557686, 'accuracy_test': 85.9375}\n",
      "58\n",
      "{'loss_train_mean': 0.029986066740114718, 'loss_train_std': 0.009923821055694249, 'accuracy_train': 90.65238558909445}\n",
      "{'loss_test': 0.0327599726151675, 'accuracy_test': 83.203125}\n",
      "59\n",
      "{'loss_train_mean': 0.02963919657464663, 'loss_train_std': 0.009906307057979855, 'accuracy_train': 90.94449853943524}\n",
      "{'loss_test': 0.029593495255539892, 'accuracy_test': 86.328125}\n",
      "60\n",
      "{'loss_train_mean': 0.029344459102281086, 'loss_train_std': 0.008976959086606047, 'accuracy_train': 90.84712755598832}\n",
      "{'loss_test': 0.028570922553626588, 'accuracy_test': 87.5}\n",
      "61\n",
      "{'loss_train_mean': 0.029308397085218593, 'loss_train_std': 0.009963834654328442, 'accuracy_train': 90.65238558909445}\n",
      "{'loss_test': 0.030147078326990595, 'accuracy_test': 85.9375}\n",
      "62\n",
      "{'loss_train_mean': 0.02912128602830117, 'loss_train_std': 0.010341320753869098, 'accuracy_train': 90.45764362220058}\n",
      "{'loss_test': 0.0297656259026553, 'accuracy_test': 85.9375}\n",
      "63\n",
      "{'loss_train_mean': 0.028878827441623237, 'loss_train_std': 0.010853260265306265, 'accuracy_train': 90.36027263875366}\n",
      "{'loss_test': 0.03472364736444433, 'accuracy_test': 81.640625}\n",
      "64\n",
      "{'loss_train_mean': 0.028677032824900216, 'loss_train_std': 0.00963027236723576, 'accuracy_train': 90.45764362220058}\n",
      "{'loss_test': 0.04565171878311958, 'accuracy_test': 76.953125}\n",
      "65\n",
      "{'loss_train_mean': 0.02873859528798336, 'loss_train_std': 0.0094532188125554, 'accuracy_train': 91.7234664070107}\n",
      "{'loss_test': 0.030154824227793142, 'accuracy_test': 85.9375}\n",
      "66\n",
      "{'loss_train_mean': 0.028320603377486736, 'loss_train_std': 0.009728945039662817, 'accuracy_train': 90.84712755598832}\n",
      "{'loss_test': 0.030361974942934467, 'accuracy_test': 85.9375}\n",
      "67\n",
      "{'loss_train_mean': 0.02810919146762641, 'loss_train_std': 0.010017910594375599, 'accuracy_train': 91.23661148977605}\n",
      "{'loss_test': 0.03136536369129317, 'accuracy_test': 84.765625}\n",
      "68\n",
      "{'loss_train_mean': 0.02782025115871892, 'loss_train_std': 0.009064458704220967, 'accuracy_train': 91.33398247322297}\n",
      "{'loss_test': 0.029274942804477178, 'accuracy_test': 86.71875}\n",
      "69\n",
      "{'loss_train_mean': 0.02759395051494385, 'loss_train_std': 0.010527350520401539, 'accuracy_train': 92.21032132424537}\n",
      "{'loss_test': 0.028870176283817273, 'accuracy_test': 87.5}\n",
      "70\n",
      "{'loss_train_mean': 0.027618576116064216, 'loss_train_std': 0.009722178747851754, 'accuracy_train': 91.43135345666991}\n",
      "{'loss_test': 0.033442483025282854, 'accuracy_test': 82.8125}\n",
      "71\n",
      "{'loss_train_mean': 0.02735084191626054, 'loss_train_std': 0.009726602327881455, 'accuracy_train': 91.62609542356378}\n",
      "{'loss_test': 0.030991816725872923, 'accuracy_test': 86.328125}\n",
      "72\n",
      "{'loss_train_mean': 0.027136276430875357, 'loss_train_std': 0.009255354117729932, 'accuracy_train': 91.91820837390458}\n",
      "{'loss_test': 0.03242642348413938, 'accuracy_test': 83.984375}\n",
      "73\n",
      "{'loss_train_mean': 0.026944843246685484, 'loss_train_std': 0.008824749835432334, 'accuracy_train': 91.82083739045764}\n",
      "{'loss_test': 0.030370956665137783, 'accuracy_test': 85.546875}\n",
      "74\n",
      "{'loss_train_mean': 0.02670808014422448, 'loss_train_std': 0.009639696161079968, 'accuracy_train': 92.01557935735151}\n",
      "{'loss_test': 0.030291422688605962, 'accuracy_test': 85.546875}\n",
      "75\n",
      "{'loss_train_mean': 0.02669593796092661, 'loss_train_std': 0.009176760725139683, 'accuracy_train': 91.91820837390458}\n",
      "{'loss_test': 0.03194988923132769, 'accuracy_test': 84.765625}\n",
      "76\n",
      "{'loss_train_mean': 0.02660640393398009, 'loss_train_std': 0.008553567800870231, 'accuracy_train': 91.62609542356378}\n",
      "{'loss_test': 0.0295583134284243, 'accuracy_test': 87.109375}\n",
      "77\n",
      "{'loss_train_mean': 0.026196379069853754, 'loss_train_std': 0.010164125527450794, 'accuracy_train': 92.01557935735151}\n",
      "{'loss_test': 0.030284146811027313, 'accuracy_test': 86.328125}\n",
      "78\n",
      "{'loss_train_mean': 0.02609412901609847, 'loss_train_std': 0.00963354379485934, 'accuracy_train': 91.52872444011685}\n",
      "{'loss_test': 0.030831486361421412, 'accuracy_test': 85.546875}\n",
      "79\n",
      "{'loss_train_mean': 0.025508120093861497, 'loss_train_std': 0.009172935364559757, 'accuracy_train': 92.79454722492697}\n",
      "{'loss_test': 0.03072742256335914, 'accuracy_test': 85.9375}\n",
      "80\n",
      "{'loss_train_mean': 0.02554184964621612, 'loss_train_std': 0.009378507700419, 'accuracy_train': 92.3076923076923}\n",
      "{'loss_test': 0.030797679311945103, 'accuracy_test': 85.9375}\n",
      "81\n",
      "{'loss_train_mean': 0.02560275274221676, 'loss_train_std': 0.008643297013638673, 'accuracy_train': 92.01557935735151}\n",
      "{'loss_test': 0.03393891899759183, 'accuracy_test': 82.421875}\n",
      "82\n",
      "{'loss_train_mean': 0.025258245261259447, 'loss_train_std': 0.009399142961315063, 'accuracy_train': 92.50243427458618}\n",
      "{'loss_test': 0.03198439444167889, 'accuracy_test': 85.546875}\n",
      "83\n",
      "{'loss_train_mean': 0.025361694116532888, 'loss_train_std': 0.009550003647827385, 'accuracy_train': 92.40506329113924}\n",
      "{'loss_test': 0.03437131560349371, 'accuracy_test': 82.03125}\n",
      "84\n",
      "{'loss_train_mean': 0.02514530006956294, 'loss_train_std': 0.009423213198204411, 'accuracy_train': 92.98928919182083}\n",
      "{'loss_test': 0.03161105423714616, 'accuracy_test': 85.9375}\n",
      "85\n",
      "{'loss_train_mean': 0.02484451661948192, 'loss_train_std': 0.009218507799228231, 'accuracy_train': 92.89191820837391}\n",
      "{'loss_test': 0.0315053645244916, 'accuracy_test': 85.9375}\n",
      "86\n",
      "{'loss_train_mean': 0.02467461403629816, 'loss_train_std': 0.008772940212642627, 'accuracy_train': 93.1840311587147}\n",
      "{'loss_test': 0.036301914409705205, 'accuracy_test': 80.859375}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# import packages\n",
    "# -----------------------------------------------------------------------------\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime \n",
    "import csv\n",
    "import configparser\n",
    "import argparse\n",
    "import platform\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from random import shuffle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load dataset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "batch_size = 10\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t\n",
    "# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "train_data_path = 'horse-or-human/horse-or-human/train'\n",
    "set_train   =   torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "loader_train = torch.utils.data.DataLoader(set_train, batch_size=batch_size, shuffle=True, num_workers=0)  \n",
    "\n",
    "\n",
    "validation_data_path = 'horse-or-human/horse-or-human/validation'\n",
    "set_test   =   torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "loader_test = torch.utils.data.DataLoader(set_test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load neural network model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "#from Linear import *\n",
    "model = Linear(num_classes=num_classes)\n",
    "#model.apply(_initialize_weight)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Set the flag for using cuda\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "bCuda = 0\n",
    "\n",
    "if bCuda:\n",
    " \n",
    "    model.cuda()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# optimization algorithm\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer   = optim.SGD(model.parameters(), lr = learning_rate, weight_decay=1e-4)\n",
    "objective   = nn.CrossEntropyLoss()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for training the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def train():\n",
    "\n",
    "    # print('train the model at given epoch')\n",
    "\n",
    "    loss_train          = []\n",
    "    correct         = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for idx_batch, (data, target) in enumerate(loader_train):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train_batch    = loss.item() / len(data)\n",
    "        loss_train.append(loss_train_batch)\n",
    "        \n",
    "        pred        = output.data.max(1)[1]\n",
    "        correct     += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss_train_mean     = np.mean(loss_train)\n",
    "    loss_train_std      = np.std(loss_train)\n",
    "    accuracy_train   = 100. * float(correct) / len(loader_train.dataset)\n",
    "    return {'loss_train_mean': loss_train_mean, 'loss_train_std': loss_train_std, 'accuracy_train': accuracy_train }\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for testing the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test():\n",
    "\n",
    "    # print('test the model at given epoch')\n",
    "\n",
    "    accuracy_test   = []\n",
    "    loss_test       = 0\n",
    "    correct         = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for idx_batch, (data, target) in enumerate(loader_test):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        loss_test   += loss.item()\n",
    "        pred        = output.data.max(1)[1]\n",
    "        correct     += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    loss_test       = loss_test / len(loader_test.dataset)\n",
    "    accuracy_test   = 100. * float(correct) / len(loader_test.dataset)\n",
    "\n",
    "    return {'loss_test': loss_test, 'accuracy_test': accuracy_test}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# iteration for the epoch\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "epoch = 6000\n",
    "\n",
    "loss_train_mean = []\n",
    "loss_train_std = []\n",
    "loss_test = []\n",
    "accuracy_test = []\n",
    "accuracy_train = []\n",
    "\n",
    "for e in range(epoch):\n",
    "        \n",
    "    result_train    = train()\n",
    "    result_test     = test()\n",
    "    \n",
    "    print(e)\n",
    "    print(result_train)\n",
    "    print(result_test)\n",
    "    \n",
    "    loss_train_mean.append(result_train['loss_train_mean'])\n",
    "    loss_train_std.append(result_train['loss_train_std'])\n",
    "    loss_test.append(result_test['loss_test'])\n",
    "    accuracy_test.append(result_test['accuracy_test'])\n",
    "    accuracy_train.append(result_train['accuracy_train'])\n",
    "    #loss_train_mean[e]  = result_train['loss_train_mean']\n",
    "    #loss_train_std[e]   = result_train['loss_train_std']\n",
    "    #loss_test[e]        = result_test['loss_test']\n",
    "    #accuracy_test[e]    = result_test['accuracy_test']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(loss_train_mean,label = \"training loss\")\n",
    "plt.plot(loss_test,label=\"test loss\")\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss') \n",
    "plt.title('Loss')\n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    "plt.plot(accuracy_train,label=\"train accuracy\")\n",
    "plt.plot(accuracy_test,label=\"test accuracy\")\n",
    "plt.xlabel('iteration')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\\ttraining\\t\\ttest\\t\\t\")\n",
    "print(\"=================================================================================\")\n",
    "print(\"loss\\t\\t\"+\"{0:.10f}\".format(loss_train_mean[-1])+\"\\t\\t\"+\"{0:.10f}\".format(loss_test[-1])+\"\\t\\t\")\n",
    "print(\"=================================================================================\")\n",
    "print(\"accuracy\\t\"+\"{0:.10f}\".format(accuracy_train[-1])+\"\\t\\t\"+ \"{0:.10f}\".format(accuracy_test[-1])+\"\\t\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
