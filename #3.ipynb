{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = 'horse-or-human/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch #numworks가 뭐지?\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1027, shuffle=False, num_workers=0)  \n",
    "\n",
    "\n",
    "validation_data_path = 'horse-or-human/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=False, num_workers=0)  \n",
    "\n",
    "NUM_EPOCH=1\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    # load training images of the batch size for every iteration\n",
    "    for i, data in enumerate(trainloader):\n",
    "\n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "        inputs, labels = data\n",
    "\n",
    "        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "        #print(inputs.shape)\n",
    "\n",
    "        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "        #print(labels)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # load validation images of the batch size for every iteration\n",
    "    for i, data in enumerate(valloader):\n",
    "        \n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "        inputs, labels = data\n",
    "\n",
    "        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "        #print(inputs.shape)\n",
    "\n",
    "        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "        #print(labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1027, 1, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = next(iter(trainloader))[0].numpy()\n",
    "train_label =next(iter(trainloader))[1].numpy()\n",
    "\n",
    "val_dataset = next(iter(valloader))[0].numpy()\n",
    "val_label =next(iter(valloader))[1].numpy()\n",
    "\n",
    "print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=train_label.reshape(1027,1)\n",
    "val_label=val_label.reshape(256,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flatten=train_dataset.reshape(1027,train_dataset.shape[2]*train_dataset.shape[3])\n",
    "val_flatten=val_dataset.reshape(256,val_dataset.shape[2]*val_dataset.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1027)\n",
      "(1, 1027)\n",
      "(10000, 256)\n",
      "(1, 256)\n"
     ]
    }
   ],
   "source": [
    "x_train=train_flatten.T\n",
    "y_train=train_label.T\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test=val_flatten.T\n",
    "y_test=val_label.T\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 1\n"
     ]
    }
   ],
   "source": [
    "n_x = x_train.shape[0] # size of input layer`\n",
    "n_h = 4 # size of hidden layer\n",
    "n_y = y_train.shape[0] # size of output layer\n",
    "print(n_x,n_y)\n",
    "m = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "\n",
    "W1 = np.random.randn(n_h,n_x) * 0.01\n",
    "b1 = np.zeros(shape=(n_h, 1))\n",
    "\n",
    "W2 = np.random.randn(n_h,n_h) * 0.01\n",
    "b2 = np.zeros(shape=(n_h, 1))\n",
    "\n",
    "W3 = np.random.randn(n_y,n_h) * 0.01\n",
    "b3 = np.zeros(shape=(n_y, 1))\n",
    "#parameters={W1, b1, W2, b2, W3, b3}\n",
    "    #return {'W1': W1,'b1':b1, 'W2':W2, 'b2':b2, 'W3':W3, 'b3':b3 }\n",
    "    #return W1, b1, W2, b2, W3, b3\n",
    "    #, W1=0, b1=0, W2=0, b2=0, W3=0, b3=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y = 1/(1+np.exp(-z))\n",
    "    return y\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_p(x_train):\n",
    "# Implement Forward Propagation to calculate A2 (probabilities)\n",
    "    #print(parameters)\n",
    "    Z1 = np.dot(W1,x_train) + b1\n",
    "    A1 = relu(Z1) # activation function\n",
    "    \n",
    "    Z2 = np.dot(W2,A1) + b2\n",
    "    A2 = relu(Z2)  #np.tanh 바꾼거\n",
    "    \n",
    "    Z3 = np.dot(W3,A2) + b3\n",
    "    A3 = sigmoid(Z3) # Final output prediction\n",
    "    return A3, A2 , A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cross-entropy cost\n",
    "def compute_cost(A3, Y):\n",
    "    loss = np.multiply(np.log(A3), Y) + np.multiply((1 - Y), np.log(1 - A3))\n",
    "    cost = - np.sum(loss) / m\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_p( X, Y, A3, A2, A1) :\n",
    "    dZ3 = A3 - Y\n",
    "    dW3 = (1 / m) * np.dot(dZ3, A2.T)\n",
    "    db3 = (1 / m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    \n",
    "    dZ2 = np.multiply(np.dot(W3.T, dZ3), 1 - np.power(A2, 2))\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    return {'dW1':dW1, 'db1':db1, 'dW2':dW2, 'db2':db2, 'dW3':dW3,'db3':db3}\n",
    "    return dW1,db1,dW2,db2,dW3,db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(  dW1=0,db1=0,dW2=0,db2=0,dW3=0,db3=0) :\n",
    "    global W1,b1,W2,b2,W3,b3,learning_rate\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W3 = W3 - learning_rate * dW3\n",
    "    b3 = b3 - learning_rate * db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict( X) :\n",
    "    A3,_,__ = forward_p(X)\n",
    "    predictions = A3 >0.5\n",
    "    \n",
    "    return predictions\n",
    "def print_accuracy(X, Y) :\n",
    "    predictions = predict( X)\n",
    "    print('Accuracy: %d' %(float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T)))/float(Y.size)*100)+ '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X, Y, n_h, num_iterations):\n",
    "    #parameters = {'W1', 'b1','W2','b2','W3','b3'}\n",
    "    #parameters = init_parameters(n_x,n_h,n_y) \n",
    "    #parameters = np.array(parameters)\n",
    "    #parameters = parameters.reshape(6,1)\n",
    "    #print('parameters', parameters.shape)\n",
    "   # print(parameters)\n",
    "    #W1 = parameters['W1']\n",
    "    #b1 = parameters['b1']\n",
    "    #W2 = parameters['W2']\n",
    "    #b2 = parameters['b2']\n",
    "    #W3 = parameters['W3']\n",
    "    #b3 = parameters['b3']\n",
    "    \n",
    "    for i in range(0, num_iterations) :\n",
    "        A3 ,A2, A1= forward_p(X)\n",
    "        cost = compute_cost(A3, Y)\n",
    "        grads = back_p( X, Y, A3, A2, A1)\n",
    "        parameters = update_parameters( **grads)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Cost after iteration %i : %f\" %(i,cost))\n",
    "            print_accuracy(X,Y)\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0 : 0.692823\n",
      "Accuracy: 51%\n",
      "Cost after iteration 100 : 0.692813\n",
      "Accuracy: 51%\n",
      "Cost after iteration 200 : 0.692807\n",
      "Accuracy: 51%\n",
      "Cost after iteration 300 : 0.692803\n",
      "Accuracy: 51%\n",
      "Cost after iteration 400 : 0.692801\n",
      "Accuracy: 51%\n",
      "Cost after iteration 500 : 0.692799\n",
      "Accuracy: 51%\n",
      "Cost after iteration 600 : 0.692798\n",
      "Accuracy: 51%\n",
      "Cost after iteration 700 : 0.692797\n",
      "Accuracy: 51%\n",
      "Cost after iteration 800 : 0.692796\n",
      "Accuracy: 51%\n",
      "Cost after iteration 900 : 0.692796\n",
      "Accuracy: 51%\n",
      "Cost after iteration 1000 : 0.692795\n",
      "Accuracy: 51%\n",
      "Cost after iteration 1100 : 0.692795\n",
      "Accuracy: 51%\n",
      "Cost after iteration 1200 : 0.692794\n",
      "Accuracy: 51%\n",
      "Cost after iteration 1300 : 0.692794\n",
      "Accuracy: 51%\n",
      "Cost after iteration 1400 : 0.692794\n",
      "Accuracy: 51%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-3acada1fa92a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mn_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-150-78fe0a2cda1f>\u001b[0m in \u001b[0;36mnn_model\u001b[1;34m(X, Y, n_h, num_iterations)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mA3\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mforward_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mback_p\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-131-035979ba4036>\u001b[0m in \u001b[0;36mback_p\u001b[1;34m(X, Y, A3, A2, A1)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdZ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdZ2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdZ1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mdb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdZ1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = nn_model(x_train, y_train ,n_h, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
