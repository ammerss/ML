{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1000], loss:0.0054603482, MSE_loss:0.1400176138\n",
      "epoch [2/1000], loss:0.0039312937, MSE_loss:0.1204736084\n",
      "epoch [3/1000], loss:0.0036951370, MSE_loss:0.1198438033\n",
      "epoch [4/1000], loss:0.0034789104, MSE_loss:0.1027563363\n",
      "epoch [5/1000], loss:0.0033985209, MSE_loss:0.1008602530\n",
      "epoch [6/1000], loss:0.0033136963, MSE_loss:0.1148618832\n",
      "epoch [7/1000], loss:0.0032461168, MSE_loss:0.0897171423\n",
      "epoch [8/1000], loss:0.0031679833, MSE_loss:0.0956600010\n",
      "epoch [9/1000], loss:0.0030784953, MSE_loss:0.0994745418\n",
      "epoch [10/1000], loss:0.0030323112, MSE_loss:0.0907550529\n",
      "epoch [11/1000], loss:0.0029792655, MSE_loss:0.1011105254\n",
      "epoch [12/1000], loss:0.0029523907, MSE_loss:0.0827395394\n",
      "epoch [13/1000], loss:0.0029024029, MSE_loss:0.0940068439\n",
      "epoch [14/1000], loss:0.0028605318, MSE_loss:0.0885569826\n",
      "epoch [15/1000], loss:0.0028194491, MSE_loss:0.0921012163\n",
      "epoch [16/1000], loss:0.0027969472, MSE_loss:0.0819711462\n",
      "epoch [17/1000], loss:0.0027742667, MSE_loss:0.0776667446\n",
      "epoch [18/1000], loss:0.0027435012, MSE_loss:0.0796818435\n",
      "epoch [19/1000], loss:0.0027209222, MSE_loss:0.0893761143\n",
      "epoch [20/1000], loss:0.0026947560, MSE_loss:0.0858917460\n",
      "epoch [21/1000], loss:0.0026718988, MSE_loss:0.0755000636\n",
      "epoch [22/1000], loss:0.0026589520, MSE_loss:0.0886562243\n",
      "epoch [23/1000], loss:0.0026287780, MSE_loss:0.0804369152\n",
      "epoch [24/1000], loss:0.0026042872, MSE_loss:0.0883980393\n",
      "epoch [25/1000], loss:0.0025954960, MSE_loss:0.0921292007\n",
      "epoch [26/1000], loss:0.0025870951, MSE_loss:0.0854751095\n",
      "epoch [27/1000], loss:0.0025605957, MSE_loss:0.0855406225\n",
      "epoch [28/1000], loss:0.0025612040, MSE_loss:0.0832389146\n",
      "epoch [29/1000], loss:0.0025228042, MSE_loss:0.0767924860\n",
      "epoch [30/1000], loss:0.0025052050, MSE_loss:0.0762496367\n",
      "epoch [31/1000], loss:0.0024896192, MSE_loss:0.0749166459\n",
      "epoch [32/1000], loss:0.0024673302, MSE_loss:0.0738031417\n",
      "epoch [33/1000], loss:0.0024580887, MSE_loss:0.0779738277\n",
      "epoch [34/1000], loss:0.0024394718, MSE_loss:0.0762585700\n",
      "epoch [35/1000], loss:0.0024256268, MSE_loss:0.0727816224\n",
      "epoch [36/1000], loss:0.0024101760, MSE_loss:0.0825588852\n",
      "epoch [37/1000], loss:0.0023860772, MSE_loss:0.0666539595\n",
      "epoch [38/1000], loss:0.0023796397, MSE_loss:0.0665585995\n",
      "epoch [39/1000], loss:0.0023732435, MSE_loss:0.0703255162\n",
      "epoch [40/1000], loss:0.0023479729, MSE_loss:0.0747463629\n",
      "epoch [41/1000], loss:0.0023379147, MSE_loss:0.0670908615\n",
      "epoch [42/1000], loss:0.0023153351, MSE_loss:0.0751814246\n",
      "epoch [43/1000], loss:0.0023048632, MSE_loss:0.0725538954\n",
      "epoch [44/1000], loss:0.0023010987, MSE_loss:0.0705721080\n",
      "epoch [45/1000], loss:0.0022848595, MSE_loss:0.0767222941\n",
      "epoch [46/1000], loss:0.0022778687, MSE_loss:0.0697368085\n",
      "epoch [47/1000], loss:0.0022544450, MSE_loss:0.0661328211\n",
      "epoch [48/1000], loss:0.0022279542, MSE_loss:0.0659234151\n",
      "epoch [49/1000], loss:0.0022362563, MSE_loss:0.0675645396\n",
      "epoch [50/1000], loss:0.0022134312, MSE_loss:0.0774919987\n",
      "epoch [51/1000], loss:0.0021921641, MSE_loss:0.0619542152\n",
      "epoch [52/1000], loss:0.0021740583, MSE_loss:0.0682954714\n",
      "epoch [53/1000], loss:0.0021626494, MSE_loss:0.0701700374\n",
      "epoch [54/1000], loss:0.0021497717, MSE_loss:0.0666281730\n",
      "epoch [55/1000], loss:0.0021448467, MSE_loss:0.0682355314\n",
      "epoch [56/1000], loss:0.0021196471, MSE_loss:0.0669514313\n",
      "epoch [57/1000], loss:0.0021390347, MSE_loss:0.0657402948\n",
      "epoch [58/1000], loss:0.0021014840, MSE_loss:0.0639243796\n",
      "epoch [59/1000], loss:0.0020838832, MSE_loss:0.0629851446\n",
      "epoch [60/1000], loss:0.0020652238, MSE_loss:0.0616411790\n",
      "epoch [61/1000], loss:0.0020637652, MSE_loss:0.0723739117\n",
      "epoch [62/1000], loss:0.0020526230, MSE_loss:0.0640976056\n",
      "epoch [63/1000], loss:0.0020223072, MSE_loss:0.0656687692\n",
      "epoch [64/1000], loss:0.0020098539, MSE_loss:0.0663378239\n",
      "epoch [65/1000], loss:0.0019936012, MSE_loss:0.0597342923\n",
      "epoch [66/1000], loss:0.0019814362, MSE_loss:0.0671303570\n",
      "epoch [67/1000], loss:0.0019631101, MSE_loss:0.0564528517\n",
      "epoch [68/1000], loss:0.0019483050, MSE_loss:0.0647727475\n",
      "epoch [69/1000], loss:0.0019309916, MSE_loss:0.0594707876\n",
      "epoch [70/1000], loss:0.0019371349, MSE_loss:0.0549407639\n",
      "epoch [71/1000], loss:0.0019065610, MSE_loss:0.0590379573\n",
      "epoch [72/1000], loss:0.0018995117, MSE_loss:0.0551837757\n",
      "epoch [73/1000], loss:0.0018727133, MSE_loss:0.0540008731\n",
      "epoch [74/1000], loss:0.0018598885, MSE_loss:0.0591004193\n",
      "epoch [75/1000], loss:0.0018480362, MSE_loss:0.0515190959\n",
      "epoch [76/1000], loss:0.0018291182, MSE_loss:0.0538993180\n",
      "epoch [77/1000], loss:0.0018110042, MSE_loss:0.0521781966\n",
      "epoch [78/1000], loss:0.0017870854, MSE_loss:0.0595673732\n",
      "epoch [79/1000], loss:0.0017914540, MSE_loss:0.0576115139\n",
      "epoch [80/1000], loss:0.0017755109, MSE_loss:0.0614801943\n",
      "epoch [81/1000], loss:0.0017453107, MSE_loss:0.0636454895\n",
      "epoch [82/1000], loss:0.0017409581, MSE_loss:0.0446540825\n",
      "epoch [83/1000], loss:0.0017045710, MSE_loss:0.0517388545\n",
      "epoch [84/1000], loss:0.0016859605, MSE_loss:0.0524561554\n",
      "epoch [85/1000], loss:0.0016660076, MSE_loss:0.0512612350\n",
      "epoch [86/1000], loss:0.0017102777, MSE_loss:0.0522254370\n",
      "epoch [87/1000], loss:0.0016652203, MSE_loss:0.0547705740\n",
      "epoch [88/1000], loss:0.0016163515, MSE_loss:0.0472599640\n",
      "epoch [89/1000], loss:0.0016025927, MSE_loss:0.0475397371\n",
      "epoch [90/1000], loss:0.0015841866, MSE_loss:0.0443299487\n",
      "epoch [91/1000], loss:0.0015654094, MSE_loss:0.0500108264\n",
      "epoch [92/1000], loss:0.0015431615, MSE_loss:0.0480227768\n",
      "epoch [93/1000], loss:0.0015569305, MSE_loss:0.0477165580\n",
      "epoch [94/1000], loss:0.0015121627, MSE_loss:0.0431583114\n",
      "epoch [95/1000], loss:0.0014908842, MSE_loss:0.0493439808\n",
      "epoch [96/1000], loss:0.0014730546, MSE_loss:0.0455904379\n",
      "epoch [97/1000], loss:0.0014659426, MSE_loss:0.0468290485\n",
      "epoch [98/1000], loss:0.0014389110, MSE_loss:0.0417441912\n",
      "epoch [99/1000], loss:0.0014138337, MSE_loss:0.0421485640\n",
      "epoch [100/1000], loss:0.0013987577, MSE_loss:0.0457190610\n",
      "epoch [101/1000], loss:0.0013776778, MSE_loss:0.0423300490\n",
      "epoch [102/1000], loss:0.0013617758, MSE_loss:0.0388352871\n",
      "epoch [103/1000], loss:0.0013457478, MSE_loss:0.0426809676\n",
      "epoch [104/1000], loss:0.0013374951, MSE_loss:0.0419436060\n",
      "epoch [105/1000], loss:0.0013299922, MSE_loss:0.0398067534\n",
      "epoch [106/1000], loss:0.0012933089, MSE_loss:0.0386466123\n",
      "epoch [107/1000], loss:0.0012728920, MSE_loss:0.0403556786\n",
      "epoch [108/1000], loss:0.0012593112, MSE_loss:0.0376257747\n",
      "epoch [109/1000], loss:0.0012383561, MSE_loss:0.0400170647\n",
      "epoch [110/1000], loss:0.0012189812, MSE_loss:0.0362695232\n",
      "epoch [111/1000], loss:0.0012142826, MSE_loss:0.0381455719\n",
      "epoch [112/1000], loss:0.0011856217, MSE_loss:0.0346325710\n",
      "epoch [113/1000], loss:0.0011599874, MSE_loss:0.0326809026\n",
      "epoch [114/1000], loss:0.0011498840, MSE_loss:0.0340462476\n",
      "epoch [115/1000], loss:0.0011313459, MSE_loss:0.0319376104\n",
      "epoch [116/1000], loss:0.0011312768, MSE_loss:0.0397277400\n",
      "epoch [117/1000], loss:0.0011139093, MSE_loss:0.0338698402\n",
      "epoch [118/1000], loss:0.0010780885, MSE_loss:0.0270811953\n",
      "epoch [119/1000], loss:0.0010619569, MSE_loss:0.0365587696\n",
      "epoch [120/1000], loss:0.0010489443, MSE_loss:0.0370003618\n",
      "epoch [121/1000], loss:0.0010341361, MSE_loss:0.0292293634\n",
      "epoch [122/1000], loss:0.0010131473, MSE_loss:0.0306549333\n",
      "epoch [123/1000], loss:0.0010023734, MSE_loss:0.0285994671\n",
      "epoch [124/1000], loss:0.0009919646, MSE_loss:0.0276695732\n",
      "epoch [125/1000], loss:0.0009702700, MSE_loss:0.0279027987\n",
      "epoch [126/1000], loss:0.0009555875, MSE_loss:0.0257704444\n",
      "epoch [127/1000], loss:0.0009376556, MSE_loss:0.0282965358\n",
      "epoch [128/1000], loss:0.0009221216, MSE_loss:0.0220043007\n",
      "epoch [129/1000], loss:0.0009055905, MSE_loss:0.0239922926\n",
      "epoch [130/1000], loss:0.0008919744, MSE_loss:0.0254262947\n",
      "epoch [131/1000], loss:0.0008933781, MSE_loss:0.0277341958\n",
      "epoch [132/1000], loss:0.0008782803, MSE_loss:0.0243118964\n",
      "epoch [133/1000], loss:0.0008532524, MSE_loss:0.0243143048\n",
      "epoch [134/1000], loss:0.0008370983, MSE_loss:0.0212012045\n",
      "epoch [135/1000], loss:0.0008260843, MSE_loss:0.0268940125\n",
      "epoch [136/1000], loss:0.0008160171, MSE_loss:0.0242071114\n",
      "epoch [137/1000], loss:0.0007987615, MSE_loss:0.0239459854\n",
      "epoch [138/1000], loss:0.0007880598, MSE_loss:0.0281062406\n",
      "epoch [139/1000], loss:0.0007852695, MSE_loss:0.0237513911\n",
      "epoch [140/1000], loss:0.0007687468, MSE_loss:0.0218657553\n",
      "epoch [141/1000], loss:0.0007503409, MSE_loss:0.0190347377\n",
      "epoch [142/1000], loss:0.0007493594, MSE_loss:0.0208174773\n",
      "epoch [143/1000], loss:0.0007257346, MSE_loss:0.0218094923\n",
      "epoch [144/1000], loss:0.0007177014, MSE_loss:0.0203570500\n",
      "epoch [145/1000], loss:0.0007004193, MSE_loss:0.0191322025\n",
      "epoch [146/1000], loss:0.0006885626, MSE_loss:0.0185247790\n",
      "epoch [147/1000], loss:0.0006901733, MSE_loss:0.0207686331\n",
      "epoch [148/1000], loss:0.0006747507, MSE_loss:0.0185153149\n",
      "epoch [149/1000], loss:0.0006838742, MSE_loss:0.0202877559\n",
      "epoch [150/1000], loss:0.0006649413, MSE_loss:0.0190699901\n",
      "epoch [151/1000], loss:0.0006490634, MSE_loss:0.0188512094\n",
      "epoch [152/1000], loss:0.0006338601, MSE_loss:0.0189342219\n",
      "epoch [153/1000], loss:0.0006251671, MSE_loss:0.0168538466\n",
      "epoch [154/1000], loss:0.0006155489, MSE_loss:0.0172854047\n",
      "epoch [155/1000], loss:0.0006042126, MSE_loss:0.0167098455\n",
      "epoch [156/1000], loss:0.0005945728, MSE_loss:0.0160091873\n",
      "epoch [157/1000], loss:0.0005814197, MSE_loss:0.0155728208\n",
      "epoch [158/1000], loss:0.0005828862, MSE_loss:0.0174262188\n",
      "epoch [159/1000], loss:0.0005685734, MSE_loss:0.0161137488\n",
      "epoch [160/1000], loss:0.0005574622, MSE_loss:0.0152240423\n",
      "epoch [161/1000], loss:0.0005500002, MSE_loss:0.0157862734\n",
      "epoch [162/1000], loss:0.0005465619, MSE_loss:0.0146700563\n",
      "epoch [163/1000], loss:0.0005372137, MSE_loss:0.0142472368\n",
      "epoch [164/1000], loss:0.0005293151, MSE_loss:0.0139857484\n",
      "epoch [165/1000], loss:0.0005214426, MSE_loss:0.0163374916\n",
      "epoch [166/1000], loss:0.0005159412, MSE_loss:0.0121835787\n",
      "epoch [167/1000], loss:0.0005097815, MSE_loss:0.0129594561\n",
      "epoch [168/1000], loss:0.0005174442, MSE_loss:0.0139346477\n",
      "epoch [169/1000], loss:0.0004982045, MSE_loss:0.0120496107\n",
      "epoch [170/1000], loss:0.0004857180, MSE_loss:0.0124310367\n",
      "epoch [171/1000], loss:0.0004925984, MSE_loss:0.0119320471\n",
      "epoch [172/1000], loss:0.0004764032, MSE_loss:0.0154278176\n",
      "epoch [173/1000], loss:0.0004676611, MSE_loss:0.0140802599\n",
      "epoch [174/1000], loss:0.0004591035, MSE_loss:0.0125712687\n",
      "epoch [175/1000], loss:0.0004484481, MSE_loss:0.0116281956\n",
      "epoch [176/1000], loss:0.0004464665, MSE_loss:0.0135396114\n",
      "epoch [177/1000], loss:0.0004490737, MSE_loss:0.0160862189\n",
      "epoch [178/1000], loss:0.0004408124, MSE_loss:0.0107918344\n",
      "epoch [179/1000], loss:0.0004300652, MSE_loss:0.0110030537\n",
      "epoch [180/1000], loss:0.0004223342, MSE_loss:0.0120880241\n",
      "epoch [181/1000], loss:0.0004188586, MSE_loss:0.0104597984\n",
      "epoch [182/1000], loss:0.0004139944, MSE_loss:0.0110828467\n",
      "epoch [183/1000], loss:0.0004084431, MSE_loss:0.0089289555\n",
      "epoch [184/1000], loss:0.0004079944, MSE_loss:0.0102405129\n",
      "epoch [185/1000], loss:0.0003991251, MSE_loss:0.0102199288\n",
      "epoch [186/1000], loss:0.0003947038, MSE_loss:0.0106701562\n",
      "epoch [187/1000], loss:0.0003991400, MSE_loss:0.0101250885\n",
      "epoch [188/1000], loss:0.0003975970, MSE_loss:0.0105558820\n",
      "epoch [189/1000], loss:0.0003872896, MSE_loss:0.0102053462\n",
      "epoch [190/1000], loss:0.0003802592, MSE_loss:0.0101902205\n",
      "epoch [191/1000], loss:0.0003741734, MSE_loss:0.0089098047\n",
      "epoch [192/1000], loss:0.0003669107, MSE_loss:0.0095938137\n",
      "epoch [193/1000], loss:0.0003726218, MSE_loss:0.0087006539\n",
      "epoch [194/1000], loss:0.0003619325, MSE_loss:0.0095912768\n",
      "epoch [195/1000], loss:0.0003520701, MSE_loss:0.0100619169\n",
      "epoch [196/1000], loss:0.0003499937, MSE_loss:0.0086895265\n",
      "epoch [197/1000], loss:0.0003627566, MSE_loss:0.0111708865\n",
      "epoch [198/1000], loss:0.0003472559, MSE_loss:0.0088275075\n",
      "epoch [199/1000], loss:0.0003458234, MSE_loss:0.0098221106\n",
      "epoch [200/1000], loss:0.0003374361, MSE_loss:0.0076877838\n",
      "epoch [201/1000], loss:0.0003327206, MSE_loss:0.0075509571\n",
      "epoch [202/1000], loss:0.0003386738, MSE_loss:0.0102336630\n",
      "epoch [203/1000], loss:0.0003336228, MSE_loss:0.0069787498\n",
      "epoch [204/1000], loss:0.0003333805, MSE_loss:0.0087572718\n",
      "epoch [205/1000], loss:0.0003239708, MSE_loss:0.0090270750\n",
      "epoch [206/1000], loss:0.0003206339, MSE_loss:0.0087805120\n",
      "epoch [207/1000], loss:0.0003180986, MSE_loss:0.0081683751\n",
      "epoch [208/1000], loss:0.0003083118, MSE_loss:0.0079353647\n",
      "epoch [209/1000], loss:0.0003087153, MSE_loss:0.0069650379\n",
      "epoch [210/1000], loss:0.0003089427, MSE_loss:0.0075217295\n",
      "epoch [211/1000], loss:0.0003041908, MSE_loss:0.0078120306\n",
      "epoch [212/1000], loss:0.0002989284, MSE_loss:0.0088676056\n",
      "epoch [213/1000], loss:0.0002995313, MSE_loss:0.0071298312\n",
      "epoch [214/1000], loss:0.0002943947, MSE_loss:0.0069375993\n",
      "epoch [215/1000], loss:0.0002913650, MSE_loss:0.0073225312\n",
      "epoch [216/1000], loss:0.0002882600, MSE_loss:0.0069279121\n",
      "epoch [217/1000], loss:0.0002929630, MSE_loss:0.0082607670\n",
      "epoch [218/1000], loss:0.0002988405, MSE_loss:0.0072290231\n",
      "epoch [219/1000], loss:0.0002931053, MSE_loss:0.0067938287\n",
      "epoch [220/1000], loss:0.0002868886, MSE_loss:0.0067831972\n",
      "epoch [221/1000], loss:0.0002808068, MSE_loss:0.0069960756\n",
      "epoch [222/1000], loss:0.0002762546, MSE_loss:0.0067227581\n",
      "epoch [223/1000], loss:0.0002777111, MSE_loss:0.0063058832\n",
      "epoch [224/1000], loss:0.0002713555, MSE_loss:0.0060864659\n",
      "epoch [225/1000], loss:0.0002672600, MSE_loss:0.0064814859\n",
      "epoch [226/1000], loss:0.0002698760, MSE_loss:0.0065181484\n",
      "epoch [227/1000], loss:0.0002717849, MSE_loss:0.0068473206\n",
      "epoch [228/1000], loss:0.0002645798, MSE_loss:0.0069850162\n",
      "epoch [229/1000], loss:0.0002589591, MSE_loss:0.0067503066\n",
      "epoch [230/1000], loss:0.0002561152, MSE_loss:0.0059719728\n",
      "epoch [231/1000], loss:0.0002555211, MSE_loss:0.0054699136\n",
      "epoch [232/1000], loss:0.0002518998, MSE_loss:0.0061445753\n",
      "epoch [233/1000], loss:0.0002532929, MSE_loss:0.0058870628\n",
      "epoch [234/1000], loss:0.0002558485, MSE_loss:0.0064087710\n",
      "epoch [235/1000], loss:0.0002539347, MSE_loss:0.0059189596\n",
      "epoch [236/1000], loss:0.0002473897, MSE_loss:0.0055328333\n",
      "epoch [237/1000], loss:0.0002443474, MSE_loss:0.0065629599\n",
      "epoch [238/1000], loss:0.0002477340, MSE_loss:0.0053563043\n",
      "epoch [239/1000], loss:0.0002474567, MSE_loss:0.0059802402\n",
      "epoch [240/1000], loss:0.0002431456, MSE_loss:0.0051566157\n",
      "epoch [241/1000], loss:0.0002433699, MSE_loss:0.0053064423\n",
      "epoch [242/1000], loss:0.0002353915, MSE_loss:0.0053404733\n",
      "epoch [243/1000], loss:0.0002388131, MSE_loss:0.0056143813\n",
      "epoch [244/1000], loss:0.0002363035, MSE_loss:0.0053675058\n",
      "epoch [245/1000], loss:0.0002337320, MSE_loss:0.0057356646\n",
      "epoch [246/1000], loss:0.0002361798, MSE_loss:0.0055542607\n",
      "epoch [247/1000], loss:0.0002326571, MSE_loss:0.0054938388\n",
      "epoch [248/1000], loss:0.0002323327, MSE_loss:0.0066167219\n",
      "epoch [249/1000], loss:0.0002387080, MSE_loss:0.0055433903\n",
      "epoch [250/1000], loss:0.0002296614, MSE_loss:0.0051432769\n",
      "epoch [251/1000], loss:0.0002265273, MSE_loss:0.0048492504\n",
      "epoch [252/1000], loss:0.0002226600, MSE_loss:0.0052368869\n",
      "epoch [253/1000], loss:0.0002231316, MSE_loss:0.0051829936\n",
      "epoch [254/1000], loss:0.0002213723, MSE_loss:0.0045726532\n",
      "epoch [255/1000], loss:0.0002242284, MSE_loss:0.0060162945\n",
      "epoch [256/1000], loss:0.0002422367, MSE_loss:0.0058558476\n",
      "epoch [257/1000], loss:0.0002234357, MSE_loss:0.0050357892\n",
      "epoch [258/1000], loss:0.0002179552, MSE_loss:0.0059255701\n",
      "epoch [259/1000], loss:0.0002162452, MSE_loss:0.0050848760\n",
      "epoch [260/1000], loss:0.0002298014, MSE_loss:0.0052996245\n",
      "epoch [261/1000], loss:0.0002177125, MSE_loss:0.0049629230\n",
      "epoch [262/1000], loss:0.0002097820, MSE_loss:0.0043892926\n",
      "epoch [263/1000], loss:0.0002103119, MSE_loss:0.0053868145\n",
      "epoch [264/1000], loss:0.0002125863, MSE_loss:0.0049905856\n",
      "epoch [265/1000], loss:0.0002077732, MSE_loss:0.0045225387\n",
      "epoch [266/1000], loss:0.0002035847, MSE_loss:0.0047977818\n",
      "epoch [267/1000], loss:0.0002043538, MSE_loss:0.0042645535\n",
      "epoch [268/1000], loss:0.0002020600, MSE_loss:0.0046717622\n",
      "epoch [269/1000], loss:0.0002043805, MSE_loss:0.0052778809\n",
      "epoch [270/1000], loss:0.0002066904, MSE_loss:0.0048502628\n",
      "epoch [271/1000], loss:0.0002041295, MSE_loss:0.0045575723\n",
      "epoch [272/1000], loss:0.0002046861, MSE_loss:0.0046677389\n",
      "epoch [273/1000], loss:0.0002001646, MSE_loss:0.0041037034\n",
      "epoch [274/1000], loss:0.0002004420, MSE_loss:0.0044665597\n",
      "epoch [275/1000], loss:0.0002029996, MSE_loss:0.0046880282\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b59a67470c42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# ===================backward====================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m#배치 사이즈 100 이고 전체 사진이 4400개이므로 포문 44번돔\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "if not os.path.exists('./training_img'):os.mkdir('./training_img')\n",
    "\n",
    "# custom dataloader for .npy file\n",
    "class numpyDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        \n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 1, 120, 80)\n",
    "    return x\n",
    "\n",
    "num_epochs = 300\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "\n",
    "def add_noise(img):\n",
    "    noise = torch.randn(img.size()) * (0.1**0.5)\n",
    "    noisy_img = img + noise\n",
    "    return noisy_img\n",
    "\n",
    "def plot_sample_img(img, name):\n",
    "    img = img.view(1, 120, 80)\n",
    "    save_image(img, './sample_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)\n",
    "\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    #transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda tensor:min_max_normalization(tensor, 0, 1)),\n",
    "    transforms.Lambda(lambda tensor:tensor_round(tensor))\n",
    "])\n",
    "\n",
    "traindata       = np.load('./train.npy')\n",
    "traindataset    = numpyDataset(traindata, img_transform)\n",
    "trainloader     = DataLoader(traindataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(120 * 80, 3200),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(3200, 800),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(800, 3200),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(3200, 120 * 80),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = autoencoder()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "loss_train_mean = []\n",
    "loss_train_std = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_train  = []\n",
    "    for data in trainloader:\n",
    "        img = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        noisy_img = add_noise(img)\n",
    "        noisy_img = Variable(noisy_img)\n",
    "        img = Variable(img)\n",
    "        # ===================forward=====================\n",
    "        output = model(noisy_img)\n",
    "        loss = criterion(output, img)\n",
    "        MSE_loss = nn.MSELoss()(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #배치 사이즈 100 이고 전체 사진이 4400개이므로 포문 44번돔\n",
    "        loss_train_batch    = MSE_loss.item() / len(noisy_img)\n",
    "        loss_train.append(loss_train_batch)\n",
    "    # ===================log========================\n",
    "    loss_train_m     = np.mean(loss_train)\n",
    "    loss_train_s      = np.std(loss_train)\n",
    "    #print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data, MSE_loss.data))\n",
    "    print('epoch [{}/{}], loss:(training) {:.10f}'.format(epoch + 1, num_epochs, loss_train_m))\n",
    "    loss_train_mean.append(loss_train_m)\n",
    "    loss_train_std.append(loss_train_s)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        x_noisy = to_img(noisy_img.cpu().data)\n",
    "        weights = to_img(model.encoder[0].weight.cpu().data)\n",
    "        save_image(x, './training_img/x_{}.png'.format(epoch))\n",
    "        save_image(x_hat, './training_img/x_hat_{}.png'.format(epoch))\n",
    "        save_image(x_noisy, './training_img/x_noisy_{}.png'.format(epoch))\n",
    "        save_image(weights, './filters/epoch_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './sim_dautoencoder.pth')\n",
    "\n",
    "testdata       = np.load('./test.npy')\n",
    "testdataset    = numpyDataset(traindata, img_transform)\n",
    "testloader     = DataLoader(traindataset, batch_size=400, shuffle=True)\n",
    "\n",
    "count = 0\n",
    "for data in testloader:\n",
    "    img = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img)\n",
    "    # ===================forward=====================\n",
    "    output = model(img)\n",
    "    #=====\n",
    "    x = to_img(img.cpu().data)\n",
    "    x_hat = to_img(output.cpu().data)\n",
    "    save_image(x, './testing_img/x_{}.png'.format(count))\n",
    "    save_image(x_hat, './testing_img/x_hat_{}.png'.format(count))\n",
    "    count += 1\n",
    "\n",
    "#the submit_file.shape must be (400,1,120,80)\n",
    "\n",
    "submit_file = x_hat.detach().numpy()\n",
    "np.save('./younkyoung20172903.npy', submit_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(loss_train_mean,label = \"training loss\")\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss') \n",
    "plt.title('Loss')\n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    "plt.plot(loss_train_std,label = \"loss std\")\n",
    "plt.title('Training standard deviation')\n",
    "plt.xlabel('iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
